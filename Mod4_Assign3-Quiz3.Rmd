---
title: "Mod4_Assign3-Quiz3-RandomForest"
author: "Grace Williams"
date: "2023-06-08"
output: word_document
editor_options: 
  chunk_output_type: console
---

##For this assignment you will need the following libraries: tidyverse, tidymodels, caret, gridExtra, vip, and ranger

```{r}
library(tidyverse)
library(tidymodels)
library(mice) #package for imputation
library(VIM) #visualizing missingness
library(ranger) #for random forests
library(randomForest) #also for random forests
library(caret)
library(skimr)
library(GGally)
library(gridExtra)
library(vip)
library(rattle)

drug <- read_csv("drug_data-2.csv")
```

##  The columns do not have names, so we’ll supply names via the names function
```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
```

## Next-up we change all CL0 and CL1 values to “No” and CL2, CL3, CL4, CL5, and CL6 values to “Yes”. CL0 and CL1 imply the drug was never used or used over a decade ago. CL2 through CL6 imply more recent drug use. The code below finds any CL0, CL1, etc. values in the data frame and replaces them with the appropriate “No” or “Yes”.
```{r}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

## Next up we do a good bit of factor conversion and recoding. Note the use of mutate_at to target specific ranges of variables. You may see a warning message about the use of the funs() function. It is OK to ignore this
```{r}
drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>% 
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54",
"55_64", "65_"))) %>%
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
  mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18",
"SomeCollege","ProfessionalCert",
"Bachelors", "Masters",
"Doctorate"))) %>%
  mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia",
"Ireland","Canada","UK"))) %>%
  mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White",
"White/Black", "Other",
"White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
  select(-ID)

str(drug_clean)
```

## We’ll focus on Nicotine use, so let’s get rid of the remaining drug use variables. We’ll use select for this.
```{r}
drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>%
  select(!(Semer:VSA))

```

## Question 1: Check for missing data in our “drug_clean” dataframe.
## True/False: There is missingness in the dataset.
### False
```{r}
which(is.na(drug_clean))
```

## Question 2: Split the dataset into training (70%) and testing (30%) sets. Use a set.seed of 1234. Stratify by the “Nicotine” variable.
## How many rows are in the training set?
### 1318
```{r}
set.seed(1234) 
drug_clean_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_clean_split)
test = testing(drug_clean_split)

nrow(train)
```

## Question 3: Create appropriate visualizations (12 in all) to examine the relationships between each variable and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups of four visualizations?).
## True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.
### TRUE
```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) +
  geom_bar(position = "fill") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) +
  geom_bar(position = "fill") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

p3 = ggplot(train, aes(x = Education, fill = Nicotine)) +
  geom_bar(position = "fill") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

p4 = ggplot(train, aes(x = Country, fill = Nicotine)) +
  geom_bar(position = "fill") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

p5 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) +
  geom_bar(position = "fill") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

grid.arrange(p1,p2,p3,p4,p5)
```

```{r}
p6 = ggplot(train, aes(x = Nicotine, y = Nscore)) +
  geom_boxplot()

p7 = ggplot(train, aes(x = Nicotine, y = Escore)) +
  geom_boxplot()

p8 = ggplot(train, aes(x = Nicotine, y = Oscore)) +
  geom_boxplot()

p9 = ggplot(train, aes(x = Nicotine, y = Ascore)) +
  geom_boxplot()

grid.arrange(p6,p7,p8,p9, ncol = 2)

```

```{r}
p10 = ggplot(train, aes(x = Nicotine, y = Cscore)) +
  geom_boxplot()

p11 = ggplot(train, aes(x = Nicotine, y = Impulsive)) +
  geom_boxplot()

p12 = ggplot(train, aes(x = Nicotine, y = SS)) +
  geom_boxplot()

grid.arrange(p10,p11,p12, ncol = 2)
```

## Question 4: True/False: Individuals with higher “Impulsive” scores more likely to be Nicotine users than not.
### TRUE

## Question 5: Create a random forest model (using the ranger package) on the training set to predict Nicotine using all of the variables in the dataset. You 5-fold, k-fold cross-validation (random number seed of 123 for the folds). Allow R to select mtry values between 2 and 8 and min_n values between 5 and 20. Use 10 levels in your “grid_regular” function. Set a random number seed of 123 for the tune_grid function. Use 100 trees.
## NOTE: This model make take a few minutes to run. Be patient. Visualize the relationships between parameters and performance metrics.

## The highest accuracy in this visualization is just greater than which value:
## A. 0.725
## B. 0.730
## C. 0.720
## D. 0.715
### B.
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

```{r}
train_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

train_rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

train_wflow = 
  workflow() %>% 
  add_model(train_rf_model) %>% 
  add_recipe(train_recipe)

train_rf_grid = grid_regular(
  mtry(range = c(2,8)),
  min_n(range = c(5,20)), 
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  train_wflow,
  resamples = rf_folds,
  grid = train_rf_grid #use the tuning grid
)
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
# OR
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
summary(rf_res_tuned)
```

## Question 6: Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the model to training set. Examine variable importance.
## Which variable is most important?
## A. Oscore
## B. Cscore
## C. Impulsive
## D. SS
### D.
```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  train_wflow,
  best_rf
)

final_rf
```
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```

## Question 7: To four decimal places, what is the accuracy of your model on the training set?
### 0.9165

## Question 8: To four decimal places, what is the naive accuracy (training set)?
### 0.6707

## Question 9: To four decimal places, what is your model’s accuracy on the testing set?
### 0.6966
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)

confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")


testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

## Question 10 The difference in accuracy on the training and testing sets implies?
## A. Overfitting does not appear to be occurring
## B. Overfitting is likely occurring
## C. It is not clear whether or not overfitting is occurring
### A